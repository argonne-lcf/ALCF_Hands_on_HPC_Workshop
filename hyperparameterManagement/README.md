<h1><span style="line-height:3.0em;font-size:1.5em;"> Hyperparameter Management <a href="https://hydra.cc"><img src="https://hydra.cc/img/logo.svg" width="10%" display="inline" style="vertical-align:middle;line-height:3.0em;margin-right:10%;" align="left" ></a> </span></h1>

**Author**: [Sam Foreman](https://samforeman.me) ([foremans@anl.gov](mailto:///foremans@anl.gov))

This section will cover some best practices / ideas related to experiment organization and hyperparameter management.

The accompanying slides for this talk can be found at: ğŸ“Š [Hyperparameter Management](https://saforem2.github.io/hparam-management-sdl2022/#/)

We use [Hydra](https://hydra.cc)[^1] for configuration management.

[^1]: [Hydra](https://hydra.cc): A framework for elegantly configuring complex applications

# Organization

```txt
ğŸ“‚ sdl_workshop/hyperparameterManagement/
â”£â”â” ğŸ“‚ src/
â”ƒ   â”—â”â” ğŸ“‚ hplib/
â”ƒ       â”£â”â” ğŸ“‚ conf/
â”ƒ       â”ƒ   â”£â”â” ğŸ“‚ data/
â”ƒ       â”ƒ   â”ƒ   â”—â”â” ğŸ“„ default.yaml
â”ƒ       â”ƒ   â”£â”â” ğŸ“‚ network/
â”ƒ       â”ƒ   â”ƒ   â”—â”â” ğŸ“„ default.yaml
â”ƒ       â”ƒ   â”£â”â” ğŸ“‚ sweeps/
â”ƒ       â”ƒ   â”ƒ   â”£â”â” ğŸ“„ max-acc-distr.yaml
â”ƒ       â”ƒ   â”ƒ   â”£â”â” ğŸ“„ max-acc-single.yaml
â”ƒ       â”ƒ   â”ƒ   â”£â”â” ğŸ“„ min-loss-distr.yaml
â”ƒ       â”ƒ   â”ƒ   â”—â”â” ğŸ“„ min-loss-single.yaml
â”ƒ       â”ƒ   â”£â”â” ğŸ“‚ trainer/
â”ƒ       â”ƒ   â”ƒ   â”—â”â” ğŸ“„ default.yaml
â”ƒ       â”ƒ   â”£â”â” ğŸ“‚ wandb/
â”ƒ       â”ƒ   â”ƒ   â”—â”â” ğŸ“„ default.yaml
â”ƒ       â”ƒ   â”—â”â” ğŸ“„ config.yaml
â”ƒ       â”£â”â” ğŸ“‚ utils/
â”ƒ       â”ƒ   â”—â”â” ğŸ pylogger.py
â”ƒ       â”£â”â” ğŸ __init__.py
â”ƒ       â”£â”â” ğŸ“„ affinity.sh
â”ƒ       â”£â”â” ğŸ configs.py
â”ƒ       â”£â”â” ğŸ main.py
â”ƒ       â”£â”â” ğŸ network.py
â”ƒ       â”£â”â” ğŸ“„ train.sh
â”ƒ       â”—â”â” ğŸ trainer.py
â”£â”â” ğŸ“„ pyproject.toml
â”£â”â” ğŸ“„ README.md
â”—â”â” ğŸ“„ setup.cfg
```

## Quick Start

1. Clone the github repo and navigate into this directory
  ```shell
  $ git clone https://github.com/argonne-lcf/sdl_workshop
  $ cd sdl_workshop/hyperparameterManagement/
  ```
  
2. Create a virtualenv and perform local install
  ```shell
  $ python3 -m venv venv
  $ source venv/bin/activate
  $ python3 -c "import hplib; print(hplib.__file__)"
  ```

3. Run experiments:
  ```shell
  $ cd src/hplib
  $ ./train.sh
  ```
  
This will perform a complete training + evaluation run using the default configurations specified in [`src/hplib/conf/config.yaml`](./src/hplib/conf/config.yaml)
